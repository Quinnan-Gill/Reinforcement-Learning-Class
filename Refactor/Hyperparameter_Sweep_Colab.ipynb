{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Sweep on Google Colab\n",
    "\n",
    "This notebook runs your RL hyperparameter experiments on Colab and saves results to Google Drive.\n",
    "\n",
    "## Setup Steps:\n",
    "1. Mount Google Drive\n",
    "2. Upload your Python files (or load from Drive)\n",
    "3. Configure hyperparameters\n",
    "4. Run sweep\n",
    "5. Generate plots\n",
    "\n",
    "**Runtime:** Use CPU (RL training doesn't benefit from GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set working directory in your Drive\n",
    "import os\n",
    "DRIVE_WORKSPACE = '/content/drive/MyDrive/RL_Experiments'\n",
    "os.makedirs(DRIVE_WORKSPACE, exist_ok=True)\n",
    "os.chdir(DRIVE_WORKSPACE)\n",
    "\n",
    "print(f\"‚úì Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Upload Your Code Files\n",
    "\n",
    "**Option A: Upload files directly to Colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"Upload these files from your local machine:\")\n",
    "print(\"  - connect_four_env.py\")\n",
    "print(\"  - perspective_state.py\")\n",
    "print(\"  - rl_agent.py\")\n",
    "print(\"  - q_learning.py\")\n",
    "print(\"  - monte_carlo.py\")\n",
    "print(\"  - sarsa.py\")\n",
    "print(\"  - train_single_config.py\")\n",
    "print(\"  - run_hyperparam_sweep.py\")\n",
    "print(\"  - analyze_hyperparam_results.py\")\n",
    "print(\"\\nClick 'Choose Files' button below...\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(f\"\\n‚úì Uploaded {len(uploaded)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option B: Load files from a Google Drive folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you've already uploaded files to Drive, specify the folder:\n",
    "CODE_FOLDER = '/content/drive/MyDrive/RL_Code'  # Adjust path\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Copy all .py files to working directory\n",
    "for filename in os.listdir(CODE_FOLDER):\n",
    "    if filename.endswith('.py'):\n",
    "        src = os.path.join(CODE_FOLDER, filename)\n",
    "        dst = os.path.join(DRIVE_WORKSPACE, filename)\n",
    "        shutil.copy(src, dst)\n",
    "        print(f\"‚úì Copied {filename}\")\n",
    "\n",
    "print(\"\\n‚úì All files loaded from Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Verify Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_files = [\n",
    "    'connect_four_env.py',\n",
    "    'perspective_state.py',\n",
    "    'rl_agent.py',\n",
    "    'q_learning.py',\n",
    "    'monte_carlo.py',\n",
    "    'sarsa.py',\n",
    "    'train_single_config.py',\n",
    "    'run_hyperparam_sweep.py',\n",
    "]\n",
    "\n",
    "missing = [f for f in required_files if not os.path.exists(f)]\n",
    "\n",
    "if missing:\n",
    "    print(\"‚ùå Missing files:\")\n",
    "    for f in missing:\n",
    "        print(f\"  - {f}\")\n",
    "else:\n",
    "    print(\"‚úì All required files present!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas numpy matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Configure Hyperparameter Sweep\n",
    "\n",
    "Edit this cell to set what you want to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read current config from run_hyperparam_sweep.py\n",
    "with open('run_hyperparam_sweep.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "print(\"HYPERPARAMETER SWEEP CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extract key configuration sections\n",
    "import re\n",
    "\n",
    "# Find BOARD_CONFIGS\n",
    "board_match = re.search(r\"BOARD_CONFIGS = \\[(.*?)\\]\", content, re.DOTALL)\n",
    "if board_match:\n",
    "    print(\"\\nBoard Configurations:\")\n",
    "    # Extract individual board configs\n",
    "    boards = re.findall(r\"\\{(.*?)\\}\", board_match.group(1), re.DOTALL)\n",
    "    for i, board in enumerate(boards, 1):\n",
    "        rows = re.search(r\"'rows': (\\d+)\", board)\n",
    "        cols = re.search(r\"'cols': (\\d+)\", board)\n",
    "        episodes = re.search(r\"'episodes': (\\d+)\", board)\n",
    "        label = re.search(r\"'label': '([^']+)'\", board)\n",
    "        if rows and cols and episodes and label:\n",
    "            print(f\"  {i}. {label.group(1)}: {rows.group(1)}√ó{cols.group(1)}, {episodes.group(1)} episodes\")\n",
    "\n",
    "# Find ALGORITHMS\n",
    "algorithms_match = re.search(r'ALGORITHMS = \\[(.*?)\\]', content, re.DOTALL)\n",
    "if algorithms_match:\n",
    "    print(\"\\nAlgorithms to Test:\")\n",
    "    print(f\"  ALGORITHMS = [{algorithms_match.group(1)}]\")\n",
    "\n",
    "# Find ALPHA_VALUES\n",
    "alpha_match = re.search(r'ALPHA_VALUES = \\[(.*?)\\]', content, re.DOTALL)\n",
    "if alpha_match:\n",
    "    print(\"\\nLearning Rates (Œ±):\")\n",
    "    print(f\"  ALPHA_VALUES = [{alpha_match.group(1)}]\")\n",
    "\n",
    "# Find GAMMA_VALUES\n",
    "gamma_match = re.search(r'GAMMA_VALUES = \\[(.*?)\\]', content, re.DOTALL)\n",
    "if gamma_match:\n",
    "    print(\"\\nDiscount Factors (Œ≥):\")\n",
    "    print(f\"  GAMMA_VALUES = [{gamma_match.group(1)}]\")\n",
    "\n",
    "# Find INITIAL_Q_VALUES\n",
    "initial_q_match = re.search(r'INITIAL_Q_VALUES = \\[(.*?)\\]', content, re.DOTALL)\n",
    "if initial_q_match:\n",
    "    print(\"\\nInitial Q-Values:\")\n",
    "    print(f\"  INITIAL_Q_VALUES = [{initial_q_match.group(1)}]\")\n",
    "\n",
    "# Find EPSILON_SCHEDULES\n",
    "epsilon_match = re.search(r'EPSILON_SCHEDULES = \\[(.*?)\\]', content, re.DOTALL)\n",
    "if epsilon_match:\n",
    "    print(\"\\nEpsilon Decay Schedules:\")\n",
    "    # Parse the schedules\n",
    "    schedules = re.findall(r'\\((.*?)\\)', epsilon_match.group(1))\n",
    "    for i, sched in enumerate(schedules, 1):\n",
    "        parts = [p.strip().strip(\"'\\\"\") for p in sched.split(',')]\n",
    "        if len(parts) >= 4:\n",
    "            print(f\"  {i}. {parts[3]:15s} - start={parts[0]}, end={parts[1]}, decay={parts[2]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüí° To change configuration:\")\n",
    "print(\"   Option A: Edit run_hyperparam_sweep.py locally and re-upload\")\n",
    "print(\"   Option B: Edit directly in Colab: !nano run_hyperparam_sweep.py\")\n",
    "print(\"             (Ctrl+O to save, Ctrl+X to exit)\")\n",
    "print(\"\\n‚ö†Ô∏è  Remember: Total runs = boards √ó algorithms √ó alphas √ó gammas √ó initial_q √ó epsilon\")\n",
    "print(\"              Minus any configs filtered by should_skip_config()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Preview Sweep Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and execute config generation to see what will run\n",
    "import importlib.util\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"sweep_module\", \"run_hyperparam_sweep.py\")\n",
    "sweep_module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(sweep_module)\n",
    "\n",
    "configs = sweep_module.generate_configs()\n",
    "\n",
    "print(f\"Total configurations to test: {len(configs)}\")\n",
    "print(f\"Estimated time: ~{len(configs) * 2} minutes ({len(configs) * 2 / 60:.1f} hours)\")\n",
    "print(f\"\\nFirst 5 configurations:\")\n",
    "for i, config in enumerate(configs[:5], 1):\n",
    "    print(f\"  {i}. {config['algorithm']}, Œ±={config['alpha']}, Œ≥={config['gamma']}, Œµ_label={config['epsilon_label']}\")\n",
    "    \n",
    "if len(configs) > 5:\n",
    "    print(f\"  ... and {len(configs)-5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Run Hyperparameter Sweep\n",
    "\n",
    "**‚ö†Ô∏è This will take 1-6 hours depending on configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sweep\n",
    "!python run_hyperparam_sweep.py\n",
    "\n",
    "# Note: The script will ask for confirmation\n",
    "# Type 'yes' when prompted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Check Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load summary\n",
    "summary_df = pd.read_csv('hyperparam_sweep/summary.csv')\n",
    "\n",
    "print(f\"Total runs completed: {len(summary_df)}\")\n",
    "print(f\"\\nTop 5 configurations by second-player performance:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top5 = summary_df.nlargest(5, 'final_win_rate_second')\n",
    "for idx, row in top5.iterrows():\n",
    "    print(f\"{row['algorithm']:12s} | Œ±={row['alpha']:4.2f} | Œ≥={row['gamma']:4.2f} | Second: {row['final_win_rate_second']:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nFull results saved to: hyperparam_sweep/summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Generate Analysis Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis script\n",
    "!python analyze_hyperparam_results.py hyperparam_sweep/\n",
    "\n",
    "print(\"\\n‚úì Plots saved to: hyperparam_sweep/analysis/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Display Plots in Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "plot_dir = 'hyperparam_sweep/analysis'\n",
    "plots = [\n",
    "    'algorithm_comparison.png',\n",
    "    'alpha_effect.png',\n",
    "    'epsilon_effect.png',\n",
    "    'convergence_analysis.png'\n",
    "]\n",
    "\n",
    "for plot in plots:\n",
    "    plot_path = os.path.join(plot_dir, plot)\n",
    "    if os.path.exists(plot_path):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(plot)\n",
    "        print('='*60)\n",
    "        display(Image(filename=plot_path))\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Plot not found: {plot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Download Results (Optional)\n",
    "\n",
    "If you want to download results to your local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip everything for easy download\n",
    "!zip -r hyperparam_results.zip hyperparam_sweep/\n",
    "\n",
    "from google.colab import files\n",
    "files.download('hyperparam_results.zip')\n",
    "\n",
    "print(\"‚úì Results packaged for download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Verify Everything Saved to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_dir_size(path):\n",
    "    \"\"\"Calculate directory size in MB.\"\"\"\n",
    "    total = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            filepath = os.path.join(dirpath, filename)\n",
    "            if os.path.exists(filepath):\n",
    "                total += os.path.getsize(filepath)\n",
    "    return total / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "sweep_dir = 'hyperparam_sweep'\n",
    "if os.path.exists(sweep_dir):\n",
    "    size_mb = get_dir_size(sweep_dir)\n",
    "    num_runs = len([d for d in os.listdir(sweep_dir) if os.path.isdir(os.path.join(sweep_dir, d)) and d.startswith('run_')])\n",
    "    \n",
    "    print(f\"‚úì Results saved in Google Drive\")\n",
    "    print(f\"\\nLocation: {os.path.abspath(sweep_dir)}\")\n",
    "    print(f\"Total size: {size_mb:.1f} MB\")\n",
    "    print(f\"Number of runs: {num_runs}\")\n",
    "    print(f\"Average per run: {size_mb/num_runs:.1f} MB\")\n",
    "    \n",
    "    # Check for summary and plots\n",
    "    if os.path.exists(os.path.join(sweep_dir, 'summary.csv')):\n",
    "        print(f\"\\n‚úì summary.csv present\")\n",
    "    \n",
    "    analysis_dir = os.path.join(sweep_dir, 'analysis')\n",
    "    if os.path.exists(analysis_dir):\n",
    "        plots = [f for f in os.listdir(analysis_dir) if f.endswith('.png')]\n",
    "        print(f\"‚úì {len(plots)} analysis plots generated\")\n",
    "else:\n",
    "    print(\"‚ùå No results directory found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Complete!\n",
    "\n",
    "Your results are saved in Google Drive at:\n",
    "```\n",
    "MyDrive/RL_Experiments/hyperparam_sweep/\n",
    "```\n",
    "\n",
    "### What You Have:\n",
    "- `summary.csv` - All results in one table\n",
    "- `analysis/*.png` - 4 analysis plots\n",
    "- `run_XXX_*/` - Individual run folders with:\n",
    "  - `config.json` - Exact hyperparameters\n",
    "  - `metrics.csv` - Episode-by-episode data\n",
    "  - `final_model.pkl` - Trained agent\n",
    "\n",
    "### Next Steps:\n",
    "1. Download `summary.csv` and analyze in Excel/Python\n",
    "2. Share plots with your partner\n",
    "3. Write paper Results section!\n",
    "\n",
    "---\n",
    "\n",
    "**Total runtime:** Check the cell execution times above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
