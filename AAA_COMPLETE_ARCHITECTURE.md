# Connect Four RL Project - Complete Architecture Map

---

## ğŸ¯ THE BIG PICTURE (What Happens When You Run)

```
YOU TYPE:
python run_project.py --agents all --episodes 5000

WHAT HAPPENS:
1. Creates environment (connect_four_env.py)
2. Trains 3 agents (q_learning.py, sarsa.py, monte_carlo.py)
   - Each inherits from rl_agent.py base class
   - Trains against random_agent.py then frozen_agent.py checkpoints
3. Evaluates all agents (evaluator.py)
   - Uses game_analyzer.py for tactical analysis
   - Uses advanced_metrics.py for quality scores
   - Uses metrics.py for statistical tests
   - Uses visualizations.py for plots
4. Saves everything (checkpoints.py, data_structures.py)
5. Prints comprehensive report
```

---

## ğŸ“Š FILE HIERARCHY (By Layer)

### **LAYER 1: Core Game Engine**
Files that define the game itself

```
connect_four_env.py
â”œâ”€â”€ Defines the game board, rules, win detection
â”œâ”€â”€ Handles move validation
â”œâ”€â”€ Tracks game state
â””â”€â”€ Used by: EVERYONE (all other files need this)
```

---

### **LAYER 2: Base Agent Framework**
Abstract base class and utilities

```
rl_agent.py (BASE CLASS)
â”œâ”€â”€ Defines Q-tables structure (red, black)
â”œâ”€â”€ Implements epsilon-greedy selection
â”œâ”€â”€ Handles save/load of models
â”œâ”€â”€ Provides get_q() and set_q() methods
â””â”€â”€ Extended by: q_learning.py, sarsa.py, monte_carlo.py
```

---

### **LAYER 3: RL Algorithm Implementations**
Concrete agents that inherit from RLModel

```
q_learning.py
â”œâ”€â”€ Inherits: RLModel
â”œâ”€â”€ Algorithm: Off-policy TD learning
â”œâ”€â”€ Update: Q(s,a) â† Q(s,a) + Î±[r + Î³ max Q(s',a') - Q(s,a)]
â””â”€â”€ Used by: run_project.py

sarsa.py
â”œâ”€â”€ Inherits: RLModel
â”œâ”€â”€ Algorithm: On-policy TD learning
â”œâ”€â”€ Update: Q(s,a) â† Q(s,a) + Î±[r + Î³ Q(s',a') - Q(s,a)]
â””â”€â”€ Used by: run_project.py

monte_carlo.py
â”œâ”€â”€ Inherits: RLModel
â”œâ”€â”€ Algorithm: Episode-based learning
â”œâ”€â”€ Update: Q(s,a) â† Q(s,a) + Î±[G - Q(s,a)] where G = sum of future rewards
â””â”€â”€ Used by: run_project.py
```

---

### **LAYER 4: Opponent Agents**
Non-learning agents used during training

```
random_agent.py
â”œâ”€â”€ Selects random valid moves
â”œâ”€â”€ Used for: Phase 1 training (vs Random)
â””â”€â”€ Called by: run_project.py training loops

frozen_agent.py
â”œâ”€â”€ Loads saved Q-tables from checkpoint
â”œâ”€â”€ Plays greedily (no exploration)
â”œâ”€â”€ Used for: Curriculum learning phases (vs past self)
â””â”€â”€ Called by: run_project.py training loops
```

---

### **LAYER 5: Training Orchestration**
The master controller

```
run_project.py â­ (THIS IS WHAT YOU RUN)
â”‚
â”œâ”€â”€ Imports:
â”‚   â”œâ”€â”€ connect_four_env.py (creates game)
â”‚   â”œâ”€â”€ q_learning.py, sarsa.py, monte_carlo.py (agents to train)
â”‚   â”œâ”€â”€ random_agent.py (Phase 1 opponent)
â”‚   â”œâ”€â”€ frozen_agent.py (Phase 3+ opponent)
â”‚   â”œâ”€â”€ evaluator.py (runs tournaments)
â”‚   â”œâ”€â”€ advanced_metrics.py (timing)
â”‚   â””â”€â”€ visualizations.py (plots)
â”‚
â”œâ”€â”€ Training Flow (Curriculum Learning):
â”‚   1. Phase 1: Train vs Random (2Ã— episodes)
â”‚   2. Phase 2: Self-play (2Ã— episodes)
â”‚   3. Phase 3: vs Phase 1 checkpoint
â”‚   4. Iteration phases: vs previous best (N times)
â”‚   5. Save final checkpoint
â”‚
â””â”€â”€ Evaluation Flow:
    1. Load all trained agents
    2. Run pairwise matchups (A vs B, B vs A)
    3. Run tournament (round-robin)
    4. Generate visualizations
    5. Save results
```

---

### **LAYER 6: Evaluation System**
Comprehensive analysis after training

```
evaluator.py (EVALUATION ORCHESTRATOR)
â”œâ”€â”€ Class: Evaluator
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ load_agent() â†’ uses evaluate.py's load_model()
â”‚   â”œâ”€â”€ run_single_game() â†’ plays one game
â”‚   â”œâ”€â”€ evaluate_matchup() â†’ plays N games, prints reports
â”‚   â””â”€â”€ run_tournament() â†’ round-robin competition
â”‚
â”œâ”€â”€ Uses:
â”‚   â”œâ”€â”€ data_structures.py (GameResult, MatchupResult)
â”‚   â”œâ”€â”€ game_analyzer.py (tactical analysis)
â”‚   â”œâ”€â”€ advanced_metrics.py (outcome metrics, quality scores)
â”‚   â”œâ”€â”€ metrics.py (statistical tests)
â”‚   â””â”€â”€ visualizations.py (plots)
â”‚
â””â”€â”€ Called by: run_project.py

evaluate.py (UTILITY FUNCTIONS)
â”œâ”€â”€ Function: load_model(workspace) â†’ loads saved agent
â”œâ”€â”€ Function: evaluate_game() â†’ simple game playing
â”œâ”€â”€ Standalone script: Can be run directly for quick tests
â””â”€â”€ Used by: evaluator.py (imports load_model)
    â””â”€â”€ NOTE: evaluator.py DEPENDS on evaluate.py for load_model()
```

---

### **LAYER 7: Analysis Modules**
Detailed game and agent analysis

```
game_analyzer.py (TACTICAL ANALYSIS)
â”œâ”€â”€ Class: GameAnalyzer
â”œâ”€â”€ Analyzes individual games for:
â”‚   â”œâ”€â”€ Winning moves taken/missed
â”‚   â”œâ”€â”€ Blocking moves made/missed
â”‚   â”œâ”€â”€ Blunders (missed opportunities)
â”‚   â””â”€â”€ Move-by-move quality
â”œâ”€â”€ Uses: data_structures.py (GameResult)
â””â”€â”€ Called by: evaluator.py, advanced_metrics.py

advanced_metrics.py (ADVANCED METRICS)
â”œâ”€â”€ Classes:
â”‚   â”œâ”€â”€ OutcomeMetrics (avg moves by win/loss/tie)
â”‚   â”œâ”€â”€ QValueStatistics (Q-table analysis)
â”‚   â”œâ”€â”€ MoveQualityScore (0-100 tactical score)
â”‚   â””â”€â”€ AdvancedMetricsAnalyzer (computes all metrics)
â”œâ”€â”€ Functions:
â”‚   â”œâ”€â”€ generate_outcome_report() â†’ formatted text
â”‚   â”œâ”€â”€ generate_quality_score_report() â†’ formatted text
â”‚   â””â”€â”€ generate_q_table_report() â†’ Q-table stats
â”œâ”€â”€ Uses: game_analyzer.py, data_structures.py
â””â”€â”€ Called by: evaluator.py (automatically during evaluation)

metrics.py (STATISTICAL ANALYSIS)
â”œâ”€â”€ Class: StatisticalAnalyzer
â”œâ”€â”€ Methods:
â”‚   â”œâ”€â”€ binomial_ci() â†’ confidence intervals
â”‚   â”œâ”€â”€ compare_win_rates() â†’ hypothesis testing
â”‚   â”œâ”€â”€ cohens_h() â†’ effect size
â”‚   â””â”€â”€ bootstrap_ci() â†’ resampling estimates
â”œâ”€â”€ Uses: data_structures.py
â””â”€â”€ Called by: evaluator.py (can be used for analysis)

visualizations.py (PLOTTING)
â”œâ”€â”€ Class: Visualizer
â”œâ”€â”€ Creates 6+ plots per matchup:
â”‚   â”œâ”€â”€ Win rate comparisons
â”‚   â”œâ”€â”€ Game length distributions
â”‚   â”œâ”€â”€ Temporal stability
â”‚   â”œâ”€â”€ Opening move preferences
â”‚   â”œâ”€â”€ Tactical accuracy
â”‚   â””â”€â”€ Column usage patterns
â”œâ”€â”€ Uses: data_structures.py
â””â”€â”€ Called by: run_project.py, evaluator.py
```

---

### **LAYER 8: Data Structures**
Shared types to avoid circular imports

```
data_structures.py (SHARED TYPES)
â”œâ”€â”€ Class: GameResult (single game data)
â”‚   â”œâ”€â”€ winner, num_moves, move_history
â”‚   â”œâ”€â”€ agent names, rewards, timestamp
â”‚   â””â”€â”€ to_dict() for JSON serialization
â”‚
â”œâ”€â”€ Class: MatchupResult (aggregated results)
â”‚   â”œâ”€â”€ red/black wins/ties
â”‚   â”œâ”€â”€ list of GameResult objects
â”‚   â””â”€â”€ computed properties (win_rate, tie_rate)
â”‚
â””â”€â”€ Used by:
    â”œâ”€â”€ evaluator.py (creates these objects)
    â”œâ”€â”€ game_analyzer.py (analyzes GameResult)
    â”œâ”€â”€ advanced_metrics.py (computes from MatchupResult)
    â”œâ”€â”€ metrics.py (statistical analysis)
    â””â”€â”€ visualizations.py (plots from data)

WHY THIS EXISTS: Breaks circular import between evaluator.py and game_analyzer.py
```

---

### **LAYER 9: Persistence**
Save and load functionality

```
checkpoints.py (SAVE/LOAD SYSTEM)
â”œâ”€â”€ Functions:
â”‚   â”œâ”€â”€ save_checkpoint() â†’ saves Q-tables
â”‚   â”œâ”€â”€ load_checkpoint() â†’ loads Q-tables
â”‚   â”œâ”€â”€ save_params() â†’ saves hyperparameters
â”‚   â””â”€â”€ load_params() â†’ loads hyperparameters
â”‚
â”œâ”€â”€ Formats supported:
â”‚   â”œâ”€â”€ Directory format: workspace/red.npz, workspace/black.npz
â”‚   â””â”€â”€ Single file format: checkpoint.save
â”‚
â””â”€â”€ Used by:
    â”œâ”€â”€ rl_agent.py (save_model, load_workspace)
    â”œâ”€â”€ evaluate.py (load_model)
    â”œâ”€â”€ frozen_agent.py (loads checkpoints)
    â””â”€â”€ All algorithm implementations
```

---

### **LAYER 10: Utilities**
Diagnostic and standalone tools

```
diagnostics.py (TESTING TOOL)
â”œâ”€â”€ Class: ConnectFourDiagnostics
â”œâ”€â”€ Functions:
â”‚   â”œâ”€â”€ count_reachable_states() â†’ state space size
â”‚   â”œâ”€â”€ analyze_terminal_states() â†’ win/loss/draw counts
â”‚   â”œâ”€â”€ test_basic_functionality() â†’ unit tests
â”‚   â””â”€â”€ sample_random_game() â†’ play random game
â””â”€â”€ Usage: Standalone tool for testing environment
    â””â”€â”€ python diagnostics.py

plot_learning_curve.py (VISUALIZATION TOOL)
â”œâ”€â”€ Function: plot_learning_curve(workspaces)
â”œâ”€â”€ Plots training progress over episodes
â””â”€â”€ Usage: Standalone tool for analyzing training
    â””â”€â”€ python plot_learning_curve.py -i workspace1 -i workspace2

run_evaluation.py (EVALUATION TOOL)
â”œâ”€â”€ Comprehensive evaluation script
â”œâ”€â”€ Modes:
â”‚   â”œâ”€â”€ matchup: Head-to-head evaluation
â”‚   â”œâ”€â”€ tournament: Multi-agent competition
â”‚   â””â”€â”€ checkpoints: Compare training checkpoints
â””â”€â”€ Usage: Alternative to run_project.py for evaluation only
    â””â”€â”€ python run_evaluation.py --mode matchup --red-agent w1 --black-agent w2
```

---

## ğŸ”„ DATA FLOW DIAGRAM

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YOU RUN: python run_project.py --agents all --episodes 5000   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: CREATE ENVIRONMENT                                     â”‚
â”‚  run_project.py â†’ connect_four_env.py                          â”‚
â”‚  Creates: ConnectFourEnv(rows=3, cols=4, connect_n=3)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: TRAIN AGENTS (for each algorithm)                     â”‚
â”‚                                                                  â”‚
â”‚  run_project.py creates:                                        â”‚
â”‚  â”œâ”€â”€ agent = QLearning(env, opts)   â† inherits from rl_agent  â”‚
â”‚  â”œâ”€â”€ opponent = RandomAgent(env)                               â”‚
â”‚  â””â”€â”€ frozen = FrozenAgent(env, checkpoint_path)                â”‚
â”‚                                                                  â”‚
â”‚  Training phases:                                               â”‚
â”‚  1. agent.train() vs random_agent                              â”‚
â”‚  2. agent.train() (self-play)                                  â”‚
â”‚  3. agent.train() vs frozen_agent (phase 1 checkpoint)         â”‚
â”‚  4. agent.train() vs frozen_agent (best checkpoint) [repeat]   â”‚
â”‚                                                                  â”‚
â”‚  Each phase:                                                    â”‚
â”‚  â”œâ”€â”€ Updates Q-tables (red, black)                             â”‚
â”‚  â””â”€â”€ Saves checkpoint â†’ checkpoints.py                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: EVALUATION                                             â”‚
â”‚                                                                  â”‚
â”‚  run_project.py â†’ evaluator.py                                 â”‚
â”‚                                                                  â”‚
â”‚  evaluator.load_agent(workspace)                               â”‚
â”‚    â†“                                                            â”‚
â”‚  evaluate.py: load_model(workspace)                            â”‚
â”‚    â†“                                                            â”‚
â”‚  checkpoints.py: load_checkpoint()                             â”‚
â”‚    â†“                                                            â”‚
â”‚  Returns: Loaded agent with Q-tables                           â”‚
â”‚                                                                  â”‚
â”‚  evaluator.evaluate_matchup(agent1, agent2, num_games=100)    â”‚
â”‚    â†“                                                            â”‚
â”‚  Plays 100 games â†’ creates GameResult objects                  â”‚
â”‚    â†“                                                            â”‚
â”‚  Stores in MatchupResult                                       â”‚
â”‚    â†“                                                            â”‚
â”‚  AUTOMATIC ANALYSIS:                                           â”‚
â”‚  â”œâ”€â”€ game_analyzer.py â†’ analyzes each game                    â”‚
â”‚  â”œâ”€â”€ advanced_metrics.py â†’ computes quality scores            â”‚
â”‚  â””â”€â”€ Prints comprehensive reports                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: VISUALIZATIONS                                         â”‚
â”‚                                                                  â”‚
â”‚  run_project.py â†’ visualizations.py                            â”‚
â”‚                                                                  â”‚
â”‚  For each matchup:                                              â”‚
â”‚  â”œâ”€â”€ Win rate bar charts                                       â”‚
â”‚  â”œâ”€â”€ Game length histograms                                    â”‚
â”‚  â”œâ”€â”€ Temporal stability plots                                  â”‚
â”‚  â”œâ”€â”€ Opening move heatmaps                                     â”‚
â”‚  â”œâ”€â”€ Tactical accuracy comparisons                             â”‚
â”‚  â””â”€â”€ Column usage patterns                                     â”‚
â”‚                                                                  â”‚
â”‚  Saves to: results/evaluations/.../plots/*.png                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: SAVE RESULTS                                           â”‚
â”‚                                                                  â”‚
â”‚  Results saved:                                                 â”‚
â”‚  â”œâ”€â”€ results/training/agent_name/                              â”‚
â”‚  â”‚   â””â”€â”€ Q-tables (red.npz, black.npz, parameters.json)        â”‚
â”‚  â”œâ”€â”€ results/evaluations/pairwise_evaluations_TIMESTAMP/       â”‚
â”‚  â”‚   â”œâ”€â”€ all_pairwise_results.json                             â”‚
â”‚  â”‚   â””â”€â”€ plots/                                                 â”‚
â”‚  â””â”€â”€ results/SUMMARY_REPORT.txt                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ CLASS INHERITANCE DIAGRAM

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RLModel           â”‚  (rl_agent.py)
â”‚   (Base Class)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ q (Q-tables)      â”‚
â”‚ â€¢ gamma, alpha, Îµ   â”‚
â”‚ â€¢ get_q(), set_q()  â”‚
â”‚ â€¢ select_action()   â”‚
â”‚ â€¢ eval_step()       â”‚
â”‚ â€¢ save_model()      â”‚
â”‚ â€¢ load_workspace()  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                 â”‚                       â”‚
       â–¼                 â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QLearning    â”‚  â”‚   Sarsa      â”‚  â”‚   MonteCarlo         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ train_step()â”‚  â”‚ â€¢ train_step()â”‚  â”‚ â€¢ generate_episode() â”‚
â”‚   Off-policy â”‚  â”‚   On-policy  â”‚  â”‚ â€¢ calculate_returns()â”‚
â”‚   TD update  â”‚  â”‚   TD update  â”‚  â”‚ â€¢ update_q_values()  â”‚
â”‚              â”‚  â”‚              â”‚  â”‚   Episode-based      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” KEY RELATIONSHIPS

### Who Calls Who?

```
run_project.py (MASTER)
â”œâ”€â”€ Creates: ConnectFourEnv
â”œâ”€â”€ Creates: QLearning, Sarsa, MonteCarlo (inherit from RLModel)
â”œâ”€â”€ Creates: RandomAgent, FrozenAgent
â”œâ”€â”€ Calls: agent.train() methods
â”œâ”€â”€ Calls: Evaluator.load_agent()
â”‚   â””â”€â”€ Which calls: evaluate.load_model()
â”‚       â””â”€â”€ Which calls: checkpoints.load_checkpoint()
â”œâ”€â”€ Calls: Evaluator.evaluate_matchup()
â”‚   â”œâ”€â”€ Which calls: GameAnalyzer.analyze_multiple_games()
â”‚   â”œâ”€â”€ Which calls: AdvancedMetricsAnalyzer methods
â”‚   â””â”€â”€ Which calls: Visualizer.plot_*()
â””â”€â”€ Saves results via checkpoints.py

evaluator.py
â”œâ”€â”€ Uses: evaluate.py (imports load_model)
â”œâ”€â”€ Uses: data_structures.py (GameResult, MatchupResult)
â”œâ”€â”€ Uses: game_analyzer.py (analyzes games)
â”œâ”€â”€ Uses: advanced_metrics.py (computes metrics)
â””â”€â”€ Creates results that metrics.py and visualizations.py can analyze

evaluate.py (DEPENDENCY of evaluator.py)
â”œâ”€â”€ Provides: load_model() function
â””â”€â”€ Used by: evaluator.py (line 58)

game_analyzer.py
â”œâ”€â”€ Uses: data_structures.py (GameResult)
â”œâ”€â”€ Uses: connect_four_env.py (replays games)
â””â”€â”€ Returns: GameAnalysis objects

advanced_metrics.py
â”œâ”€â”€ Uses: data_structures.py (GameResult, MatchupResult)
â”œâ”€â”€ Uses: game_analyzer.py (GameAnalysis)
â””â”€â”€ Returns: Formatted reports (printed to console)

data_structures.py
â”œâ”€â”€ Used by: evaluator.py, game_analyzer.py, advanced_metrics.py
â”œâ”€â”€ Used by: metrics.py, visualizations.py
â””â”€â”€ Purpose: Breaks circular imports
```

---

## ğŸ¯ WHICH FILES DO YOU NEED?

### **CRITICAL (Cannot run without these):**
```
âœ… connect_four_env.py       - The game
âœ… rl_agent.py                - Base class for algorithms
âœ… q_learning.py              - Algorithm
âœ… sarsa.py                   - Algorithm  
âœ… monte_carlo.py             - Algorithm
âœ… random_agent.py            - Training opponent
âœ… frozen_agent.py            - Training opponent
âœ… checkpoints.py             - Save/load system
âœ… run_project.py             - Master orchestrator
âœ… evaluator.py               - Evaluation framework
âœ… evaluate.py                - Provides load_model() to evaluator
âœ… data_structures.py         - Shared types
âœ… game_analyzer.py           - Tactical analysis
âœ… advanced_metrics.py        - Quality metrics
âœ… metrics.py                 - Statistical analysis
âœ… visualizations.py          - Plotting
```

### **OPTIONAL (Utility tools):**
```
âšª diagnostics.py             - Testing tool (run independently)
âšª plot_learning_curve.py     - Visualization tool (run independently)
âšª run_evaluation.py          - Alternative evaluation script
```

---

## ğŸ“‹ SUMMARY TABLE

| File | Layer | Purpose | Used By | Depends On |
|------|-------|---------|---------|------------|
| `connect_four_env.py` | 1 - Core | Game engine | Everyone | - |
| `rl_agent.py` | 2 - Base | Base agent class | Algorithm files | connect_four_env |
| `q_learning.py` | 3 - Algorithms | Q-Learning agent | run_project | rl_agent |
| `sarsa.py` | 3 - Algorithms | SARSA agent | run_project | rl_agent |
| `monte_carlo.py` | 3 - Algorithms | Monte Carlo agent | run_project | rl_agent |
| `random_agent.py` | 4 - Opponents | Random opponent | run_project | connect_four_env |
| `frozen_agent.py` | 4 - Opponents | Checkpoint opponent | run_project | connect_four_env, checkpoints |
| `run_project.py` | 5 - Orchestration | **Main script** | **You** | All of above + evaluator |
| `evaluator.py` | 6 - Evaluation | Evaluation framework | run_project | evaluate, data_structures, game_analyzer, advanced_metrics |
| `evaluate.py` | 6 - Evaluation | Load utility | evaluator | checkpoints, rl_agent |
| `game_analyzer.py` | 7 - Analysis | Tactical analysis | evaluator, advanced_metrics | data_structures, connect_four_env |
| `advanced_metrics.py` | 7 - Analysis | Quality metrics | evaluator | data_structures, game_analyzer |
| `metrics.py` | 7 - Analysis | Statistical tests | evaluator (optional) | data_structures |
| `visualizations.py` | 7 - Analysis | Plotting | run_project, evaluator | data_structures |
| `data_structures.py` | 8 - Data | Shared types | All analysis modules | - |
| `checkpoints.py` | 9 - Persistence | Save/load | rl_agent, evaluate, frozen_agent | - |
| `diagnostics.py` | 10 - Utils | Testing tool | Standalone | connect_four_env |
| `plot_learning_curve.py` | 10 - Utils | Plot training | Standalone | - |
| `run_evaluation.py` | 10 - Utils | Evaluation tool | Standalone | evaluator |

---

## ğŸ’¡ KEY INSIGHTS

1. **evaluate.py vs evaluator.py confusion:**
   - `evaluate.py` = Utility functions (especially `load_model`)
   - `evaluator.py` = Comprehensive framework (Evaluator class)
   - `evaluator.py` DEPENDS on `evaluate.py` (line 58 import)
   - **Both are needed**

2. **data_structures.py exists to break circular imports:**
   - Without it: evaluator.py imports from game_analyzer.py AND game_analyzer.py imports from evaluator.py = ERROR
   - With it: Both import from data_structures.py = works

3. **The 3 layers of evaluation:**
   - Layer 1: `evaluator.py` orchestrates
   - Layer 2: `game_analyzer.py` analyzes tactics
   - Layer 3: `advanced_metrics.py` computes scores
   - All use `data_structures.py` to communicate

4. **Why so many files:**
   - Separation of concerns
   - Each file has ONE clear responsibility
   - Makes testing easier
   - Makes future changes easier

---

## ğŸš€ WHAT HAPPENS WHEN YOU RUN

**Command:**
```bash
python run_project.py --agents all --episodes 5000
```

**Step-by-step execution:**

1. **Parse arguments** (run_project.py lines 1-50)
2. **Create environment** (connect_four_env.py)
3. **For each algorithm** (Q-Learning, SARSA, Monte Carlo):
   - Create agent instance (inherits from rl_agent.py)
   - Run curriculum training phases:
     - Phase 1: vs random_agent.py
     - Phase 2: self-play
     - Phase 3: vs frozen_agent.py (past checkpoint)
     - Iterations: vs frozen_agent.py (best checkpoint)
   - Save final checkpoint (checkpoints.py)
4. **Load all trained agents:**
   - Uses evaluator.py â†’ evaluate.py â†’ checkpoints.py
5. **Run pairwise evaluations:**
   - Uses evaluator.py
   - Each game creates GameResult (data_structures.py)
   - Aggregates into MatchupResult (data_structures.py)
   - Automatically analyzes:
     - Tactical quality (game_analyzer.py)
     - Outcome metrics (advanced_metrics.py)
     - Statistical tests (metrics.py - optional)
6. **Generate visualizations:**
   - Uses visualizations.py
   - Creates 6+ plots per matchup
7. **Run tournament:**
   - Uses evaluator.py
   - Round-robin all agents
8. **Save everything:**
   - JSON results
   - Plots
   - Summary report


